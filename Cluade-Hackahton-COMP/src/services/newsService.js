import { supabase } from "@/lib/supabase";

// Mock LLM response for now since we don't have a backend
const mockLLMResponse = {
    summary: "This is a simulated summary of the news topic. In a real implementation, this would be generated by an AI model analyzing multiple articles.",
    key_points: [
        "Key point 1 about the situation",
        "Key point 2 regarding the impact",
        "Key point 3 on future outlook"
    ],
    left_emphasis: ["Focus on social impact"],
    right_emphasis: ["Focus on economic cost"],
    common_ground: ["Everyone agrees it is important"],
    tags: ["Politics", "Canada"]
};

export const newsService = {
    async getTopics() {
        // First, get topics that have CBC articles
        const { data: cbcArticles, error: articleError } = await supabase
            .from('news_articles')
            .select('topic')
            .ilike('source', '%CBC%');

        if (articleError) throw articleError;

        // Extract unique topic names
        const topicNames = [...new Set(cbcArticles.map(a => a.topic))];

        if (topicNames.length === 0) return [];

        const { data, error } = await supabase
            .from('news_topics')
            .select('*')
            .in('topic', topicNames)
            .order('created_at', { ascending: false })
            .limit(20);

        if (error) throw error;
        return data;
    },

    async fetchAndAnalyzeNews() {
        console.log("Invoking fetch-rss-news Edge Function...");

        const { data, error } = await supabase.functions.invoke('fetch-rss-news');

        if (error) {
            console.error("Error invoking function:", error);
            throw error;
        }

        console.log("Edge function response:", data);
        return data;
    }
};
